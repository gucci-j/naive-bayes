{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB映画レビュー感情分類\n",
    "===\n",
    "肯定/否定を分類するナイーブベイズをベースとしたモデルの構築を目指す．  \n",
    "参照：https://keras.io/ja/datasets/  \n",
    "\n",
    "## IMDBデータセットについて\n",
    "感情 (肯定/否定) のラベル付けをされた，25,000のIMDB映画レビューのデータセット．  \n",
    "レビューは前処理済みで，各レビューは単語のインデックス（整数）のシーケンスとしてエンコードされています．  \n",
    "便宜上，単語はデータセットにおいての出現頻度によってインデックスされています．  \n",
    "そのため例えば，整数\"3\"はデータの中で3番目に頻度が多い単語にエンコードされます．  \n",
    "これによって\"上位20個の頻出語を除いた，上位10,000個の頻出語についてのみ考える\"というようなフィルタリング作業を高速に行うことができます．  \n",
    "慣例として，\"0\"は特定の単語を表さずに，未知語にエンコードされます．\n",
    "\n",
    "### メモ\n",
    "* num_words: 出現頻度が上位num_wordsの単語のみをデータとして用いる\n",
    "* oov_char: 置換対象の単語をoov_charで置き換える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Atsuki/.pyenv/versions/3.6.2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from keras.datasets import imdb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot encodingについて\n",
    "ある文中で，1万語収録の辞書に登録されている単語があれば，該当の単語番号に1を立てる．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "def OneHotEncoding(sequence, dimension=10000):\n",
    "    temp = np.zeros((len(sequence), dimension))\n",
    "    for i, j in enumerate(sequence):\n",
    "        temp[i, j] = 1.\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
    "        num_words=10000, skip_top=0, maxlen=None, start_char=1, oov_char=2, index_from=3)\n",
    "    # One-Hot Encoding\n",
    "    x_train = OneHotEncoding(x_train, 10000)\n",
    "    x_test = OneHotEncoding(x_test, 10000)\n",
    "    # convert to numpy arrays\n",
    "    y_train = np.asarray(y_train).astype('float32')\n",
    "    y_test = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learnのナイーブベイズ系関数について\n",
    "ナイーブベイズでは，求めたい確率分布がどのような分布になるかによって，いくつかの種類がある．  \n",
    "つまり，事前分布を決めなくてはならないということである．3種類あるので，以下に示す．\n",
    "1. ガウス分布\n",
    "2. ベルヌーイ分布\n",
    "3. 多項式分布  \n",
    "\n",
    "通常，文書分類では入力データが多次元となり，各要素自体も実数値で表現されるので，3の多項式分布が用いられる．  \n",
    "しかしながら，今回はすでにone-hot encodingを済ませているので，ベルヌーイ分布を仮定する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.868\n",
      "Test accuracy: 0.840\n"
     ]
    }
   ],
   "source": [
    "    model = BernoulliNB()\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Train accuracy: {:.3f}'.format(model.score(x_train, y_train)))\n",
    "    print('Test accuracy: {:.3f}'.format(model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 総評\n",
    "なかなかの結果がでましたね．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
